# -*- coding: utf-8 -*-
"""bs_scrapper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pn7c9-67XGArrcSTIBCgUc6dU2SP97XF
"""

# Importing required libraries
from bs4 import BeautifulSoup as bs4 
import requests # For getting the source code
import pandas as pd

# Creating lists
pages=[]
prices=[]
stars=[]
titles=[]
urlss=[]

# Variable to store number of pages to scrape
pages_to_scrape=5

# Code to scrape n number of pages
for i in range(1,pages_to_scrape+1):
    url = ('http://books.toscrape.com/catalogue/page-{}.html').format(i) # We only need to increment the  page number(Rest all is same)
    pages.append(url) # Take all the links collected and append it to the list named pages[]

# Parsing the data
for item in pages:
    page = requests.get(item) # Without indentation
    soup = bs4(page.text, 'html.parser') # With HTML indentation and store it in soup

# Getting the title which lies in the HTML h tag
    for i in soup.findAll('h3'):
        ttl=i.getText() # Getting only text in h tag
        titles.append(ttl)

# In soup file find p and class_='price_color' and  get text from it
    for j in soup.findAll('p', class_='price_color'):
        price=j.getText()
        prices.append(price)

# Star rating is in class attribute in form of k,v pair
    for s in soup.findAll('p', class_='star-rating'):
        for k,v in s.attrs.items():
            star =v[1] # Getting second element of value
            stars.append(star)

# First find div and image_container then find img and thumbnail
    divs =soup.findAll('div', class_='image_container')
    for thumbs in divs:
        tgs=thumbs.find('img',class_='thumbnail')
        urls='http://books.toscrape.com/'+str(tgs['src']) # Go in img, thumbnail and extract tag src from it
        newurls=urls.replace("../","")
        urlss.append(newurls)

# Creating a dictionary
Data={'Title': titles, 'Prices': prices, 'Stars':stars, "URLs":urlss}
#print(Data)

# Converting it into a dataframe
df=pd.DataFrame(data=Data)

df.index+=1
df

# Creating an excel sheet 
df.to_excel(r'C:\Users\Deep\Desktop\Movie Recommendation Engine\output.xlsx')